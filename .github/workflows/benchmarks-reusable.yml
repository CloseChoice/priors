name: ASV Benchmarks (Reusable)

on:
  workflow_call:
    inputs:
      deploy_to_pages:
        description: 'Deploy results to GitHub Pages'
        required: false
        type: boolean
        default: false
      cache_key_prefix:
        description: 'Prefix for cache key (e.g., test, prod)'
        required: false
        type: string
        default: 'asv'

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for ASV

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install asv virtualenv

      - name: Restore ASV results cache
        uses: actions/cache@v4
        with:
          path: .asv/results
          key: ${{ inputs.cache_key_prefix }}-results-${{ github.ref_name }}-${{ github.sha }}
          restore-keys: |
            ${{ inputs.cache_key_prefix }}-results-${{ github.ref_name }}-
            ${{ inputs.cache_key_prefix }}-results-main-
            ${{ inputs.cache_key_prefix }}-results-

      - name: Configure ASV machine
        run: |
          echo "Configuring ASV machine..."

          # Use asv machine command to register the machine non-interactively
          echo -e "\n\n\n\n\n\n" | asv machine --yes || {
            echo "Warning: asv machine command failed, trying alternative approach..."

            # Fallback: Create machine config manually
            MACHINE_NAME=$(hostname)
            mkdir -p .asv
            cat > .asv/asv-machine.json << EOF
          {
            "$MACHINE_NAME": {
              "arch": "x86_64",
              "cpu": "GitHub Actions Runner",
              "machine": "$MACHINE_NAME",
              "num_cpu": "2",
              "os": "Linux",
              "ram": "7GB",
              "version": 1
            }
          }
          EOF
          }

          echo "âœ… ASV machine configuration complete"

      - name: Run benchmarks
        run: |
          set -e

          echo "ðŸ” Checking for existing benchmark results..."

          # Get machine name for ASV
          MACHINE_NAME=$(hostname)
          echo "Using machine: $MACHINE_NAME"

          # Set ASV to use the machine without interactive prompt
          export ASV_MACHINE="$MACHINE_NAME"

          # Strategy for incremental benchmarks:
          # 1. If results exist: Only benchmark NEW commits (since last run)
          # 2. If no results: Full benchmark from 0.1.0 release (5adfd57)
          # 3. Fallback: Always benchmark HEAD as minimum

          if [ -f .asv/results/benchmarks.json ] && [ -d .asv/results/*/  ]; then
            echo "âœ… Found cached results, running incremental benchmarks..."
            echo "ðŸ“Š This will only benchmark NEW commits since last run (much faster!)"

            # Try incremental benchmark
            if asv run NEW --show-stderr --quick --machine="$MACHINE_NAME"; then
              echo "âœ… Incremental benchmark completed"
            else
              echo "âš ï¸  No new commits to benchmark, ensuring HEAD is benchmarked..."
              asv run HEAD^! --show-stderr --quick --machine="$MACHINE_NAME" || true
            fi
          else
            echo "ðŸ†• No previous results found - running initial full benchmark"
            echo "ðŸ“¦ Benchmarking from v0.1.0 (5adfd57) onwards to avoid Python 3.10 compatibility issues"
            echo "â±ï¸  This will take ~5-10 minutes for the first run..."

            # Full benchmark from 0.1.0 release
            asv run 5adfd57..HEAD --show-stderr --quick --machine="$MACHINE_NAME" || {
              echo "âš ï¸  Some commits failed to build, continuing..."
              # Ensure at least HEAD is benchmarked
              asv run HEAD^! --show-stderr --quick --machine="$MACHINE_NAME"
            }
          fi

          # Verify HEAD was benchmarked
          echo "ðŸ” Verifying HEAD commit is benchmarked..."
          asv run HEAD^! --show-stderr --quick --machine="$MACHINE_NAME" || echo "âš ï¸  HEAD already benchmarked"

          echo "âœ… Benchmark run completed!"

      - name: Store results as artifact
        uses: actions/upload-artifact@v4
        with:
          # Use cache_key_prefix instead of branch name to avoid / in artifact name
          # Branch names like ci/benchmarking contain / which is not allowed
          name: asv-results-${{ inputs.cache_key_prefix }}-${{ github.sha }}
          path: .asv/results/
          retention-days: 90

      - name: Download existing results from gh-pages
        if: inputs.deploy_to_pages == true
        continue-on-error: true
        run: |
          echo "ðŸ“¥ Downloading existing benchmark results from gh-pages..."

          # Fetch gh-pages branch
          git fetch origin gh-pages || {
            echo "â„¹ï¸  No gh-pages branch yet, this will be the first deployment"
            exit 0
          }

          # Check if .asv/results exists on gh-pages
          if git ls-tree -r origin/gh-pages --name-only | grep -q "^\.asv/results/"; then
            echo "âœ… Found existing results on gh-pages"

            # Create temp directory and extract results
            mkdir -p /tmp/gh-pages-results
            git archive origin/gh-pages .asv/results | tar -x -C /tmp/gh-pages-results

            # Merge with current results (don't overwrite new results)
            if [ -d "/tmp/gh-pages-results/.asv/results" ]; then
              cp -rn /tmp/gh-pages-results/.asv/results/* .asv/results/ 2>/dev/null || true
              echo "âœ… Merged existing results with new results"
            fi

            rm -rf /tmp/gh-pages-results
          else
            echo "â„¹ï¸  No existing results found in gh-pages"
          fi

      - name: Generate HTML report
        run: |
          echo "ðŸ“Š Generating HTML report from benchmark results..."

          # Important: We keep ALL branches in asv.conf.json for multi-branch support
          # ASV will now see results from all branches and generate the branch selector
          CURRENT_BRANCH="${GITHUB_REF_NAME}"
          echo "Current branch: $CURRENT_BRANCH"

          # Generate HTML with all branches - ASV will create selector if multiple branches exist
          asv publish || {
            echo "âš ï¸  asv publish had warnings, but continuing..."
          }

          echo "âœ… HTML report generated in .asv/html/"
          echo "ðŸ“Š Branch selector will show all branches with available results"

      - name: Create .nojekyll file
        run: touch .asv/html/.nojekyll

      - name: Copy results to HTML directory for gh-pages
        if: inputs.deploy_to_pages == true
        run: |
          echo "ðŸ“‹ Copying benchmark results to HTML directory..."
          # Copy results so they persist on gh-pages
          cp -r .asv/results .asv/html/.asv/results
          echo "âœ… Results copied to .asv/html/.asv/results"

      - name: Upload HTML for deployment
        if: inputs.deploy_to_pages == true
        uses: actions/upload-artifact@v4
        with:
          name: asv-html-${{ github.sha }}
          path: .asv/html/
          retention-days: 1

      - name: Generate benchmark summary
        if: always()
        run: |
          echo "## ðŸ“Š Benchmark Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f .asv/results/benchmarks.json ]; then
            # Count total benchmarks
            RESULT_FILES=$(find .asv/results -name "*.json" -not -name "benchmarks.json" | wc -l)
            echo "âœ… Generated $RESULT_FILES result files" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Show recent commits that were benchmarked
            echo "### Recent Benchmarked Commits" >> $GITHUB_STEP_SUMMARY
            git log -5 --oneline >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            if [ "${{ inputs.deploy_to_pages }}" == "true" ]; then
              echo "ðŸ“ˆ View full results at: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/" >> $GITHUB_STEP_SUMMARY
            else
              echo "ðŸ“¦ Results stored as artifact (no deployment)" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "âš ï¸ No benchmark results generated" >> $GITHUB_STEP_SUMMARY
          fi

  deploy:
    name: Deploy to GitHub Pages
    needs: benchmark
    if: inputs.deploy_to_pages == true
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pages: write
      id-token: write
    steps:
      - name: Download HTML artifact
        uses: actions/download-artifact@v4
        with:
          name: asv-html-${{ github.sha }}
          path: .asv/html/

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: .asv/html
          keep_files: true  # Keep files from other branches for multi-branch support
          user_name: 'github-actions[bot]'
          user_email: 'github-actions[bot]@users.noreply.github.com'
          commit_message: 'Update benchmarks from ${{ github.ref_name }} @ ${{ github.sha }}'

      - name: Deployment summary
        run: |
          echo "## ðŸš€ Deployment Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“ˆ Benchmarks deployed to GitHub Pages" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— View at: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Branch: \`${{ github.ref_name }}\`" >> $GITHUB_STEP_SUMMARY
