name: ASV Benchmarks (Reusable)

on:
  workflow_call:
    inputs:
      deploy_to_pages:
        description: "Deploy results to GitHub Pages"
        required: false
        type: boolean
        default: false
      cache_key_prefix:
        description: "Prefix for cache key (e.g., test, prod)"
        required: false
        type: string
        default: "asv"

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Full history for ASV

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install asv virtualenv

      - name: Restore ASV results cache
        uses: actions/cache@v4
        with:
          path: .asv/results
          key: ${{ inputs.cache_key_prefix }}-results-${{ github.ref_name }}-${{ github.sha }}
          restore-keys: |
            ${{ inputs.cache_key_prefix }}-results-${{ github.ref_name }}-
            ${{ inputs.cache_key_prefix }}-results-main-
            ${{ inputs.cache_key_prefix }}-results-

      - name: Configure ASV machine
        run: |
          echo "Configuring ASV machine..."

          # Use asv machine command to register the machine non-interactively
          echo -e "\n\n\n\n\n\n" | asv machine --yes || {
            echo "Warning: asv machine command failed, trying alternative approach..."

            # Fallback: Create machine config manually
            MACHINE_NAME=$(hostname)
            mkdir -p .asv
            cat > .asv/asv-machine.json << EOF
          {
            "$MACHINE_NAME": {
              "arch": "x86_64",
              "cpu": "GitHub Actions Runner",
              "machine": "$MACHINE_NAME",
              "num_cpu": "2",
              "os": "Linux",
              "ram": "7GB",
              "version": 1
            }
          }
          EOF
          }

          echo "‚úÖ ASV machine configuration complete"

      - name: Run benchmarks
        run: |
          set -e

          echo "üîç Checking for existing benchmark results..."

          # Get machine name for ASV
          MACHINE_NAME=$(hostname)
          echo "Using machine: $MACHINE_NAME"

          # Set ASV to use the machine without interactive prompt
          export ASV_MACHINE="$MACHINE_NAME"

          # Strategy for incremental benchmarks:
          # 1. If results exist: Only benchmark NEW commits (since last run)
          # 2. If no results: Full benchmark from 0.1.0 release (5adfd57)
          # 3. Fallback: Always benchmark HEAD as minimum

          if [ -f .asv/results/benchmarks.json ] && [ -d .asv/results/*/  ]; then
            echo "‚úÖ Found cached results, running incremental benchmarks..."
            echo "üìä This will only benchmark NEW commits since last run (much faster!)"

            # Try incremental benchmark
            if asv run NEW --show-stderr --quick --machine="$MACHINE_NAME"; then
              echo "‚úÖ Incremental benchmark completed"
            else
              echo "‚ö†Ô∏è  No new commits to benchmark, ensuring HEAD is benchmarked..."
              asv run HEAD^! --show-stderr --quick --machine="$MACHINE_NAME" || true
            fi
          else
            echo "üÜï No previous results found - running initial full benchmark"
            echo "üì¶ Benchmarking from v0.1.0 (5adfd57) onwards to avoid Python 3.10 compatibility issues"
            echo "‚è±Ô∏è  This will take ~5-10 minutes for the first run..."

            # Full benchmark from 0.1.0 release
            asv run 5adfd57..HEAD --show-stderr --quick --machine="$MACHINE_NAME" || {
              echo "‚ö†Ô∏è  Some commits failed to build, continuing..."
              # Ensure at least HEAD is benchmarked
              asv run HEAD^! --show-stderr --quick --machine="$MACHINE_NAME"
            }
          fi

          # Verify HEAD was benchmarked
          echo "üîç Verifying HEAD commit is benchmarked..."
          asv run HEAD^! --show-stderr --quick --machine="$MACHINE_NAME" || echo "‚ö†Ô∏è  HEAD already benchmarked"

          echo "‚úÖ Benchmark run completed!"

      - name: Sanitize branch name for artifact
        id: sanitize_branch
        run: |
          SANITIZED_BRANCH=$(echo "${{ github.ref_name }}" | tr '/' '-')
          echo "sanitized_branch=$SANITIZED_BRANCH" >> $GITHUB_OUTPUT

      - name: Store results as artifact
        uses: actions/upload-artifact@v4
        with:
          name: asv-results-${{ steps.sanitize_branch.outputs.sanitized_branch }}-${{ github.sha }}
          path: .asv/results/
          retention-days: 90

      - name: Download existing results from gh-pages (branch-scoped)
        if: inputs.deploy_to_pages == true
        continue-on-error: true
        run: |
          echo "üì• Downloading existing benchmark results for this branch from gh-pages..."

          SANITIZED=${{ steps.sanitize_branch.outputs.sanitized_branch }}

          # Fetch gh-pages branch
          git fetch origin gh-pages || {
            echo "‚ÑπÔ∏è  No gh-pages branch yet, this will be the first deployment"
            exit 0
          }

          # Prefer branch-scoped results stored at .asv/html/.asv/results/<branch>/ on gh-pages
          TARGET_PATH=".asv/html/.asv/results/${SANITIZED}"

          if git ls-tree -r origin/gh-pages --name-only | grep -q "^${TARGET_PATH}/"; then
            echo "‚úÖ Found branch-scoped results at ${TARGET_PATH} on gh-pages"

            mkdir -p /tmp/gh-pages-results
            # Extract only the branch-scoped results
            git archive origin/gh-pages ${TARGET_PATH} | tar -x -C /tmp/gh-pages-results

            # If extracted, merge into local .asv/results so ASV can use them for incremental runs
            if [ -d "/tmp/gh-pages-results/${TARGET_PATH}" ]; then
              echo "üîÅ Merging branch results into local .asv/results/"
              mkdir -p .asv/results
              cp -rn /tmp/gh-pages-results/${TARGET_PATH}/* .asv/results/ 2>/dev/null || true
              echo "‚úÖ Merged branch results for ${SANITIZED}"
            fi

            rm -rf /tmp/gh-pages-results
          else
            echo "‚ÑπÔ∏è  No branch-scoped results found for ${SANITIZED} on gh-pages; attempting legacy .asv/results/ merge"

            # Fallback to legacy top-level .asv/results on gh-pages (backwards compatibility)
            if git ls-tree -r origin/gh-pages --name-only | grep -q "^\.asv/results/"; then
              echo "‚ö†Ô∏è  Found legacy .asv/results on gh-pages ‚Äî merging ALL results (this may include other branches)"
              mkdir -p /tmp/gh-pages-results
              git archive origin/gh-pages .asv/results | tar -x -C /tmp/gh-pages-results
              if [ -d "/tmp/gh-pages-results/.asv/results" ]; then
                cp -rn /tmp/gh-pages-results/.asv/results/* .asv/results/ 2>/dev/null || true
                echo "‚úÖ Merged legacy results"
              fi
              rm -rf /tmp/gh-pages-results
            else
              echo "‚ÑπÔ∏è  No existing results found in gh-pages"
            fi
          fi

      - name: Generate HTML report
        run: |
          echo "üìä Generating HTML report from benchmark results..."

          # Important: We keep ALL branches in asv.conf.json for multi-branch support
          # ASV will now see results from all branches and generate the branch selector
          CURRENT_BRANCH="${GITHUB_REF_NAME}"
          echo "Current branch: $CURRENT_BRANCH"

          # Generate HTML with all branches - ASV will create selector if multiple branches exist
          asv publish || {
            echo "‚ö†Ô∏è  asv publish had warnings, but continuing..."
          }

          echo "‚úÖ HTML report generated in .asv/html/"
          echo "üìä Branch selector will show all branches with available results"

      - name: Create .nojekyll file
        run: touch .asv/html/.nojekyll

      - name: Copy results to HTML directory for gh-pages (branch-scoped)
        if: inputs.deploy_to_pages == true
        run: |
          echo "üìã Copying benchmark results to HTML directory (branch-scoped)..."
          SANITIZED=${{ steps.sanitize_branch.outputs.sanitized_branch }}

          # Create target dir for this branch inside the html artifact
          mkdir -p .asv/html/.asv/results/${SANITIZED}

          # Copy current results into branch-specific folder so gh-pages stores per-branch results
          cp -r .asv/results/* .asv/html/.asv/results/${SANITIZED}/ 2>/dev/null || true

          echo "‚úÖ Results copied to .asv/html/.asv/results/${SANITIZED}"

      - name: Add custom branch selector
        if: inputs.deploy_to_pages == true
        run: |
          echo "üìã Adding custom branch selector interface..."

          # Copy branch selector HTML if it exists
          if [ -f "asv-branch-selector.html" ]; then
            cp asv-branch-selector.html .asv/html/branches.html
            echo "‚úÖ Branch selector added at /branches.html"
          else
            echo "‚ö†Ô∏è  asv-branch-selector.html not found, skipping"
          fi

      - name: Generate branch comparison reports
        if: inputs.deploy_to_pages == true
        continue-on-error: true
        run: |
          echo "üìä Generating branch comparison reports..."

          # Get all branches that have been benchmarked
          BENCHMARKED_BRANCHES=$(cat asv.conf.json | python3 -c "import sys, json; branches = json.load(sys.stdin).get('branches', []); print(' '.join([b for b in branches if '**' not in b]))" 2>/dev/null || echo "main improve-speed")

          echo "Branches to compare: $BENCHMARKED_BRANCHES"

          # Create comparisons directory
          mkdir -p .asv/html/comparisons

          # Generate pairwise comparisons
          BRANCH_ARRAY=($BENCHMARKED_BRANCHES)
          for i in "${!BRANCH_ARRAY[@]}"; do
            for j in "${!BRANCH_ARRAY[@]}"; do
              if [ $i -lt $j ]; then
                BRANCH1="${BRANCH_ARRAY[$i]}"
                BRANCH2="${BRANCH_ARRAY[$j]}"

                echo "Comparing $BRANCH1 vs $BRANCH2..."

                # Run ASV compare and save to file
                asv compare "$BRANCH1" "$BRANCH2" > ".asv/html/comparisons/${BRANCH1//\//_}_vs_${BRANCH2//\//_}.txt" 2>&1 || {
                  echo "‚ö†Ô∏è  Comparison failed (branches may not have overlapping commits)"
                  echo "Comparison unavailable: branches may not have overlapping commits" > ".asv/html/comparisons/${BRANCH1//\//_}_vs_${BRANCH2//\//_}.txt"
                }
              fi
            done
          done

          echo "‚úÖ Branch comparisons generated in .asv/html/comparisons/"

      - name: Upload HTML for deployment
        if: inputs.deploy_to_pages == true
        uses: actions/upload-artifact@v4
        with:
          name: asv-html-${{ github.sha }}
          path: .asv/html/
          retention-days: 1

      - name: Generate benchmark summary
        if: always()
        run: |
          echo "## üìä Benchmark Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f .asv/results/benchmarks.json ]; then
            # Count total benchmarks
            RESULT_FILES=$(find .asv/results -name "*.json" -not -name "benchmarks.json" | wc -l)
            echo "‚úÖ Generated $RESULT_FILES result files" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Show recent commits that were benchmarked
            echo "### Recent Benchmarked Commits" >> $GITHUB_STEP_SUMMARY
            git log -5 --oneline >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            if [ "${{ inputs.deploy_to_pages }}" == "true" ]; then
              echo "üìà View full results at: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/" >> $GITHUB_STEP_SUMMARY
            else
              echo "üì¶ Results stored as artifact (no deployment)" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "‚ö†Ô∏è No benchmark results generated" >> $GITHUB_STEP_SUMMARY
          fi

  deploy:
    name: Deploy to GitHub Pages
    needs: benchmark
    if: inputs.deploy_to_pages == true
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pages: write
      id-token: write
    steps:
      - name: Download HTML artifact
        uses: actions/download-artifact@v4
        with:
          name: asv-html-${{ github.sha }}
          path: .asv/html/

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: .asv/html
          keep_files: true # Keep files from other branches for multi-branch support
          force_orphan: false # Don't force orphan to preserve history
          enable_jekyll: false # Disable Jekyll to allow dotfiles
          user_name: "github-actions[bot]"
          user_email: "github-actions[bot]@users.noreply.github.com"
          commit_message: "Update benchmarks from ${{ github.ref_name }} @ ${{ github.sha }}"

      - name: Deployment summary
        run: |
          echo "## üöÄ Deployment Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "üìà Benchmarks deployed to GitHub Pages" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "üîó View at: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Branch: \`${{ github.ref_name }}\`" >> $GITHUB_STEP_SUMMARY
