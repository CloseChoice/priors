#!/usr/bin/env python3

import time
import numpy as np
import pandas as pd
import psutil
import os
import tracemalloc
from typing import Optional, Tuple

try:
    import priors
    HAS_PRIORS = True
except ImportError:
    HAS_PRIORS = False
    print("âš ï¸  priors not installed")

try:
    from mlxtend.frequent_patterns import fpgrowth as mlxtend_fpgrowth
    HAS_MLXTEND = True
except ImportError:
    HAS_MLXTEND = False
    print("âš ï¸  mlxtend not installed")

try:
    from efficient_apriori import apriori as efficient_apriori
    HAS_EFFICIENT_APRIORI = True
except ImportError:
    HAS_EFFICIENT_APRIORI = False
    print("âš ï¸  efficient-apriori not installed")


def get_memory_mb():
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024


def generate_transactions(num_transactions: int, num_items: int,
                         avg_items_per_tx: int, density: float = 0.7) -> np.ndarray:
    np.random.seed(42)
    data = np.zeros((num_transactions, num_items), dtype=np.int32)

    for i in range(num_transactions):
        num_items_in_tx = int(avg_items_per_tx * (0.5 + np.random.random()))
        num_items_in_tx = min(num_items_in_tx, num_items)

        if np.random.random() < density:
            items = np.random.choice(num_items, size=num_items_in_tx, replace=False)
            data[i, items] = 1

    return data


def benchmark_with_memory(name: str, func, *args, timeout=300, **kwargs) -> Optional[dict]:
    print(f"\n  Testing {name}...", end='', flush=True)

    mem_before = get_memory_mb()
    tracemalloc.start()

    start = time.time()
    try:
        result = func(*args, **kwargs)
        elapsed = time.time() - start
        print(f" âœ“ {elapsed:.2f}s")

        current, peak = tracemalloc.get_traced_memory()
        tracemalloc.stop()
        mem_after = get_memory_mb()

        if isinstance(result, list):
            patterns = sum(len(level) for level in result)
        elif isinstance(result, pd.DataFrame):
            patterns = len(result)
        elif isinstance(result, tuple):
            patterns = sum(len(result[0][k]) for k in result[0])
        else:
            patterns = 0

        return {
            'library': name,
            'time': elapsed,
            'patterns': patterns,
            'memory_before_mb': mem_before,
            'memory_after_mb': mem_after,
            'memory_delta_mb': mem_after - mem_before,
            'peak_traced_mb': peak / 1024 / 1024,
            'status': 'success'
        }
    except MemoryError:
        tracemalloc.stop()
        print(f"    âŒ OOM!")
        return {
            'library': name,
            'status': 'oom',
            'memory_before_mb': mem_before,
        }
    except Exception as e:
        tracemalloc.stop()
        print(f"    âŒ Error: {str(e)}")
        return {
            'library': name,
            'status': 'error',
            'error': str(e),
        }


def test_priors_regular(transactions, min_support):
    return priors.fp_growth(transactions, min_support)


def test_priors_lazy(transactions, min_support, chunk_size=5000):
    processor_id = priors.create_lazy_fp_growth()

    num_transactions = transactions.shape[0]
    num_chunks = (num_transactions + chunk_size - 1) // chunk_size

    for chunk_idx in range(num_chunks):
        start_idx = chunk_idx * chunk_size
        end_idx = min((chunk_idx + 1) * chunk_size, num_transactions)
        chunk = transactions[start_idx:end_idx]
        priors.lazy_count_pass(processor_id, chunk)

    priors.lazy_finalize_counts(processor_id, min_support)

    for chunk_idx in range(num_chunks):
        start_idx = chunk_idx * chunk_size
        end_idx = min((chunk_idx + 1) * chunk_size, num_transactions)
        chunk = transactions[start_idx:end_idx]
        priors.lazy_build_pass(processor_id, chunk)

    result = priors.lazy_mine_patterns(processor_id, min_support)
    stats = priors.lazy_get_stats(processor_id)

    priors.lazy_cleanup(processor_id)

    return result


def test_mlxtend(transactions, min_support):
    df = pd.DataFrame(transactions.astype(bool),
                     columns=[f"item_{i}" for i in range(transactions.shape[1])])
    return mlxtend_fpgrowth(df, min_support=min_support, use_colnames=True)


def test_efficient_apriori(transactions, min_support):
    tx_list = [list(np.where(row == 1)[0]) for row in transactions]
    return efficient_apriori(tx_list, min_support=min_support)


def run_oom_stress_tests():
    print("\n" + "="*80)
    print("ğŸ”¥ OOM Stress Test: Pushing Libraries to Their Limits")
    print("="*80)

    configs = [
        {
            'name': '50K Ã— 80 (Warm-up)',
            'num_transactions': 50_000,
            'num_items': 80,
            'avg_size': 40,
            'density': 0.85,
            'min_support': 0.005
        },
        {
            'name': '100K Ã— 100 (Dense)',
            'num_transactions': 100_000,
            'num_items': 100,
            'avg_size': 60,
            'density': 0.9,
            'min_support': 0.003
        },
        {
            'name': '200K Ã— 120 (Heavy)',
            'num_transactions': 200_000,
            'num_items': 120,
            'avg_size': 80,
            'density': 0.85,
            'min_support': 0.002
        },
    ]

    all_results = []

    for config in configs:
        print(f"\n{'='*80}")
        print(f"ğŸ“Š Dataset: {config['name']}")
        print(f"   Transactions: {config['num_transactions']:,}")
        print(f"   Items: {config['num_items']:,}")
        print(f"   Avg Size: {config['avg_size']}")
        print(f"   Density: {config['density']}")
        print(f"   Min Support: {config['min_support']}")
        print(f"{'='*80}")

        transactions = generate_transactions(
            config['num_transactions'],
            config['num_items'],
            config['avg_size'],
            config['density']
        )

        dataset_mb = transactions.nbytes / 1024 / 1024
        print(f"   Dataset size: {dataset_mb:.2f} MB")

        if HAS_MLXTEND:
            result = benchmark_with_memory(
                'mlxtend',
                test_mlxtend,
                transactions,
                config['min_support']
            )
            if result:
                result['config'] = config['name']
                all_results.append(result)
                if result['status'] == 'success':
                    print(f"    âœ“ Time: {result['time']:.2f}s | Memory: {result['memory_delta_mb']:.1f}MB | Patterns: {result['patterns']}")

        if HAS_EFFICIENT_APRIORI:
            result = benchmark_with_memory(
                'efficient-apriori',
                test_efficient_apriori,
                transactions,
                config['min_support']
            )
            if result:
                result['config'] = config['name']
                all_results.append(result)
                if result['status'] == 'success':
                    print(f"    âœ“ Time: {result['time']:.2f}s | Memory: {result['memory_delta_mb']:.1f}MB | Patterns: {result['patterns']}")

        if HAS_PRIORS:
            result = benchmark_with_memory(
                'priors (regular)',
                test_priors_regular,
                transactions,
                config['min_support']
            )
            if result:
                result['config'] = config['name']
                all_results.append(result)
                if result['status'] == 'success':
                    print(f"    âœ“ Time: {result['time']:.2f}s | Memory: {result['memory_delta_mb']:.1f}MB | Patterns: {result['patterns']}")

            result = benchmark_with_memory(
                'priors (lazy)',
                test_priors_lazy,
                transactions,
                config['min_support']
            )
            if result:
                result['config'] = config['name']
                all_results.append(result)
                if result['status'] == 'success':
                    print(f"    âœ“ Time: {result['time']:.2f}s | Memory: {result['memory_delta_mb']:.1f}MB | Patterns: {result['patterns']}")

    return pd.DataFrame(all_results)


def test_extreme_low_support():
    print("\n" + "="*80)
    print("ğŸ’¥ Extreme Low Support Test (Pattern Explosion)")
    print("="*80)

    transactions = generate_transactions(30_000, 100, 60, 0.85)
    support_levels = [0.01, 0.005, 0.002, 0.001]

    results = []

    for min_support in support_levels:
        print(f"\n  Min Support: {min_support}")

        if HAS_PRIORS:
            result = benchmark_with_memory(
                f'priors (support={min_support})',
                test_priors_regular,
                transactions,
                min_support
            )
            if result:
                result['min_support'] = min_support
                results.append(result)
                if result['status'] == 'success':
                    print(f"    Patterns: {result['patterns']:,} | Memory: {result['memory_delta_mb']:.1f}MB")
                    if result['patterns'] > 1_000_000:
                        print(f"    âš ï¸  Pattern explosion detected!")

    return pd.DataFrame(results)


if __name__ == '__main__':
    if not HAS_PRIORS:
        print("âŒ priors not available, cannot run tests")
        exit(1)

    print("ğŸ§ª Starting OOM and Memory Stress Tests")
    print(f"ğŸ’» System Memory: {psutil.virtual_memory().total / 1024 / 1024 / 1024:.1f} GB")
    print(f"ğŸ“Š Available Memory: {psutil.virtual_memory().available / 1024 / 1024 / 1024:.1f} GB\n")

    oom_results = run_oom_stress_tests()
    explosion_results = test_extreme_low_support()

    print("\n" + "="*80)
    print("ğŸ“Š OOM Test Summary")
    print("="*80)

    if not oom_results.empty:
        success_df = oom_results[oom_results['status'] == 'success']
        if not success_df.empty:
            print("\nâœ… Successful Runs:")
            summary = success_df.groupby('library').agg({
                'time': ['mean', 'max'],
                'memory_delta_mb': ['mean', 'max'],
                'patterns': 'sum'
            }).round(2)
            print(summary)

        oom_df = oom_results[oom_results['status'] == 'oom']
        if not oom_df.empty:
            print("\nâŒ OOM Failures:")
            print(oom_df[['library', 'config']])

        oom_results.to_csv('oom_stress_results.csv', index=False)
        print("\nğŸ’¾ Results saved to: oom_stress_results.csv")

    if not explosion_results.empty:
        explosion_results.to_csv('pattern_explosion_results.csv', index=False)
        print("ğŸ’¾ Pattern explosion results saved to: pattern_explosion_results.csv")
